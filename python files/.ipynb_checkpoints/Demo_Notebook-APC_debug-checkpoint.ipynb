{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder2(table,df1_col,df2_col):\n",
    "    df1=table.drop(table.columns[min(df2_col):],axis=1)\n",
    "    df2=table.drop(table.columns[min(df1_col):min(df2_col)],axis=1)\n",
    "    return (df1,df2)\n",
    "\n",
    "def reorder3(table,df1_col,df2_col,df3_col):\n",
    "    df1=table.drop(table.columns[min(df2_col):],axis=1)\n",
    "    df2=table.drop(table.columns[min(df1_col):min(df2_col)].union(table.columns[min(df3_col):]),axis=1)\n",
    "    df3=table.drop(table.columns[min(df1_col):min(df3_col)],axis=1)\n",
    "\n",
    "    return (df1,df2,df3)\n",
    "\n",
    "def verticalSplit_instrument(table_list, kw1='collar',kw2='swap'):\n",
    "\n",
    "    '''\n",
    "    Takes a list of tables and attempts to split them.\n",
    "    Returns a new table_list that has the original tables split, if needed.\n",
    "    '''\n",
    "    split_dfs = []\n",
    "    transformation_dict = {}\n",
    "    #print(len(table_list))\n",
    "    for table in table_list:\n",
    "#         print('-'*10,'original table','-'*10)\n",
    "#         display(HTML(table.to_html()))\n",
    "        table = table.rename(str.lower, axis = \"columns\")\n",
    "        for _ in range(3):\n",
    "            table_columns = table.columns\n",
    "            # we want the columns that have either the word 'oil' or 'bbl' in the column, but we want to omit columns that\n",
    "            # have information purely about gas, ie, either 'gas' or 'btu'. We then add these two queries together, and remove\n",
    "            # the columns that are duplicates between oil_cols and oil_cols2.\n",
    "            # We then create a oil_cols, which we make sure does not have ANY gas information in it.\n",
    "            collar_cols = [i for i,col in enumerate(table_columns) if (kw1 in col and kw2 not in col)]\n",
    "            swap_cols = [i for i,col in enumerate(table_columns) if (kw2 in col and kw1 not in col)]\n",
    "#             print(collar_cols,swap_cols)\n",
    "\n",
    "            # if we have BOTH columns that ONLY HAVE oil information and gas information, we continue.\n",
    "            if collar_cols!=[] and swap_cols!=[]:\n",
    "                if min(collar_cols)<min(swap_cols): #first oil then gas and hten ngl \n",
    "                    df1,df2=reorder2(table,collar_cols,swap_cols)\n",
    "                if min(collar_cols)>min(swap_cols):  \n",
    "                    df1,df2=reorder2(table,swap_cols,collar_cols)\n",
    "                split_dfs.append(df1)\n",
    "                table=df2\n",
    "                \n",
    "            else: break\n",
    "        split_dfs.append(table)\n",
    "        \n",
    "    return split_dfs\n",
    "\n",
    "\n",
    "def verticalSplit_ZLU(table_list, verbose = False):\n",
    "\n",
    "    '''\n",
    "    Takes a list of tables and attempts to split them.\n",
    "    Returns a new table_list that has the original tables split, if needed.\n",
    "    '''\n",
    "    split_dfs = []\n",
    "    transformation_dict = {}\n",
    "    verbose=True\n",
    "    #print(len(table_list))\n",
    "    for table in table_list:\n",
    "#         print('-'*10,'original table','-'*10)\n",
    "#         display(HTML(table.to_html()))\n",
    "        table = table.rename(str.lower, axis = \"columns\")\n",
    "        table_columns = table.columns\n",
    "        # we want the columns that have either the word 'oil' or 'bbl' in the column, but we want to omit columns that\n",
    "        # have information purely about gas, ie, either 'gas' or 'btu'. We then add these two queries together, and remove\n",
    "        # the columns that are duplicates between oil_cols and oil_cols2.\n",
    "        # We then create a oil_cols, which we make sure does not have ANY gas information in it.\n",
    "        oil_cols = [i for i,col in enumerate(table_columns) if ((\"oil\" in col or 'bbl' in col or 'barrel' in col) and ((\"ngl\" not in col)  and (\"gas\" not in col) and ('btu' not in col)))]\n",
    "\n",
    "\n",
    "        # this is the same process as above, but flipped.\n",
    "        gas_cols = [i for i,col in enumerate(table_columns) if ((\"gas\" in col or 'btu' in col) and ((\"ngl\" not in col) and (\"oil\" not in col) and ('bbl' not in col)))]\n",
    "        \n",
    "        ngl_cols = [i for i,col in enumerate(table_columns) if (\"ngl\" in col and \"oil\" not in col)]\n",
    "        # if we have BOTH columns that ONLY HAVE oil information and gas information, we continue.\n",
    "        if min(len(oil_cols),1)+min(1,len(gas_cols))+min(1,len(ngl_cols))==3:\n",
    "        \n",
    "            if min(oil_cols)<min(gas_cols)<min(ngl_cols): #first oil then gas and hten ngl \n",
    "                df1,df2,df3=reorder3(table,oil_cols,gas_cols,ngl_cols)\n",
    "            if min(oil_cols)<min(ngl_cols)<min(gas_cols):  \n",
    "                df1,df2,df3=reorder3(table,oil_cols,ngl_cols,gas_cols)\n",
    "            if min(gas_cols)<min(oil_cols)<min(ngl_cols):  \n",
    "                df1,df2,df3=reorder3(table,gas_cols,oil_cols,ngl_cols)\n",
    "            # add the newly split dfs to a new list, that we will eventually return.\n",
    "            split_dfs.append(df1)\n",
    "            split_dfs.append(df2)\n",
    "            split_dfs.append(df3)\n",
    "        elif oil_cols!=[] and gas_cols!=[]:\n",
    "            if min(oil_cols)<min(gas_cols): #first oil then gas and hten ngl \n",
    "                df1,df2=reorder2(table,oil_cols,gas_cols)\n",
    "            if min(oil_cols)>min(gas_cols):  \n",
    "                df1,df2=reorder2(table,gas_cols,oil_cols)\n",
    "            split_dfs.append(df1)\n",
    "            split_dfs.append(df2)\n",
    "        elif oil_cols!=[] and ngl_cols!=[]:\n",
    "            if min(oil_cols)<min(ngl_cols): #first oil then gas and hten ngl \n",
    "                df1,df2=reorder2(table,oil_cols,ngl_cols)\n",
    "            if min(oil_cols)>min(ngl_cols):  \n",
    "                df1,df2=reorder2(table,ngl_cols,oil_cols)\n",
    "            split_dfs.append(df1)\n",
    "            split_dfs.append(df2)\n",
    "        elif gas_cols!=[] and ngl_cols!=[]:\n",
    "            if min(gas_cols)<min(ngl_cols): #first oil then gas and hten ngl \n",
    "                df1,df2=reorder2(table,gas_cols,ngl_cols)\n",
    "            if min(gas_cols)>min(ngl_cols):  \n",
    "                df1,df2=reorder2(table,ngl_cols,gas_cols)\n",
    "            split_dfs.append(df1)\n",
    "            split_dfs.append(df2)\n",
    "        \n",
    "        else:\n",
    "            split_dfs.append(table)\n",
    "    return split_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict, Counter\n",
    "# def vertically_stacked_subtable_cleaner(dictionary, flagged_dict, debug = False):\n",
    "#     '''\n",
    "#     This function does two things:\n",
    "#     1) Appends the splitted subtables to the list where the subtables are contained in\n",
    "#     2) Deletes the original subtables\n",
    "\n",
    "#     dictionary: dictionary with file_header as keys and list of dataframes as values\n",
    "#     flagged_dict: output from get_vertically_stacked_subtables()\n",
    "#     '''\n",
    "\n",
    "#     debug_dict = defaultdict(list)\n",
    "\n",
    "# ### Append subtables to original list under respective tickers\n",
    "#     for ticker, indices in flagged_dict.items():\n",
    "#         for index in indices:\n",
    "#             df_original = dictionary[ticker][index]\n",
    "#             # Create a temp version of df that removes parentheses and everything within it, for each cell\n",
    "\n",
    "# #             print('\\n')\n",
    "#             # Assuming we don't have to split more than fifteen times per dataframe\n",
    "#             for _ in range(15):\n",
    "#                 for x_idx in range(df_original.shape[0]):\n",
    "#                     df_temp = df_original.applymap(lambda x: re.sub(r'\\([^()]*\\)', \"\", x))\n",
    "#                     # Find the first row index to split on, based of df_temp\n",
    "#                     # The row must satisfy two conditions (1. no numbers within any cells, 2. the entine row not consist of only empty strings)\n",
    "#                     if (not any(df_temp.iloc[x_idx].str.contains('\\d'))) & (not all(df_temp.iloc[x_idx] == '')):\n",
    "#                         break\n",
    "#                 # If it's not a subtable anymore, break\n",
    "#                 if (x_idx + 1) == df_original.shape[0]:\n",
    "#                     break\n",
    "#                 # We don't wanna split on the last row\n",
    "#                 if x_idx == range(df_original.shape[0])[-1]:\n",
    "#                     break\n",
    "# #                 print('*******Original Dictionary*******')\n",
    "# #                 print(ticker, index)\n",
    "# #                 display(HTML(df_original.to_html()))\n",
    "# #                 print(x_idx)\n",
    "#                 df_split1 = df_original.iloc[:x_idx]\n",
    "#                 df_split2 = df_original.iloc[x_idx:]\n",
    "#                 # Keep the original columns as series for further usage\n",
    "#                 columns_temp = df_split2.columns\n",
    "#                 # Clear the columns to use set_col_header function\n",
    "#                 df_split2.columns = [\"\" for x in columns_temp]\n",
    "#                 if not any(df_split2.iloc[0,1:].str.contains('\\d')):\n",
    "#                     df_split2.columns=df_split2.iloc[0]\n",
    "#                     df_split2=df_split2.iloc[1:]\n",
    "#                 df_split2 = set_col_headers(df_split2)\n",
    "#                 # Use original columns if empty OR if the new would_have_been column names are contained in columns_temp, or else, stick with the new ones\n",
    "#                 df_split2.columns = [columns_temp[k] if (re.search('[\\w]',v) == None or v in columns_temp[k]) else v for k,v in enumerate(df_split2.columns)]\n",
    "#                 dictionary[ticker].append(df_split1)\n",
    "# #                 print('*******Trimmed Dictionary*******')\n",
    "# #                 display(HTML(df_split1.to_html()))\n",
    "#                 debug_dict[ticker].append(df_split1)\n",
    "#                 df_original = df_split2\n",
    "#             # Grab the final piece of the dataframe\n",
    "#             dictionary[ticker].append(df_original)\n",
    "# #             display(HTML(df_split2.to_html()))\n",
    "# #             print('\\n')\n",
    "# #             print('\\n')\n",
    "# #             print('*'*50)\n",
    "#             debug_dict[ticker].append(df_split2)\n",
    "\n",
    "# ### Delete the original subtables\n",
    "#     if debug == False:\n",
    "#         for k in flagged_dict.keys():\n",
    "#             target_list = dictionary[k]\n",
    "#             to_be_del = list(flagged_dict[k])\n",
    "#             to_be_del.sort(reverse=True)\n",
    "#             for index in to_be_del:\n",
    "#                 del target_list[index]\n",
    "#     else:\n",
    "#         return debug_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertically_stacked_subtable_cleaner(dictionary, flagged_dict, exclusion=False, excluded_ticker=None):\n",
    "    '''\n",
    "    This function does two things:\n",
    "    1) Appends the splitted subtables to the list where the subtables are contained in\n",
    "    2) Deletes the original subtables\n",
    "\n",
    "    dictionary: dictionary with file_header as keys and list of dataframes as values\n",
    "    flagged_dict: output from get_vertically_stacked_subtables()\n",
    "    exclusion: whether to exclude certain company within the flagged_dict or not\n",
    "    excluded_ticker: the tickers to be excluded, as a typle of strings\n",
    "    '''\n",
    "\n",
    "    if exclusion == True:\n",
    "        flagged_dict = {k: v for k, v in flagged_dict.items() if not k.startswith(excluded_ticker)}\n",
    "\n",
    "### Append subtables to original list under respective tickers\n",
    "    for ticker, indices in flagged_dict.items():\n",
    "        for index in indices:\n",
    "            df_original = dictionary[ticker][index]\n",
    "            print(ticker,index)\n",
    "            display(HTML(df_original.to_html()))\n",
    "            # Assuming we don't have to split more than fifteen times per dataframe\n",
    "            for _ in range(15):\n",
    "                for x_idx in range(df_original.shape[0]):\n",
    "                    # Create a temp version of df that removes parentheses and everything within it, for each cell\n",
    "                    df_temp = df_original.applymap(lambda x: re.sub(r'\\([^()]*\\)', \"\", x))\n",
    "                    # Find the first row index to split on, based of df_temp\n",
    "                    # The row must satisfy two conditions (1. no numbers within any cells, 2. the entine row not consist of only empty strings)\n",
    "                    if (not any(df_temp.iloc[x_idx].str.contains('\\d'))) & (not all(df_temp.iloc[x_idx] == '')):\n",
    "                        break\n",
    "                # If it's not a subtable anymore, break\n",
    "                if (x_idx + 1) == df_original.shape[0]:\n",
    "                    break\n",
    "                # We don't wanna split on the last row\n",
    "                if x_idx == range(df_original.shape[0])[-1]:\n",
    "                    break\n",
    "                if df_original.shape[1]==1: break\n",
    "                df_split1 = df_original.iloc[:x_idx]\n",
    "                df_split2 = df_original.iloc[x_idx:]\n",
    "                # Keep the original columns as series for further usage\n",
    "                columns_temp = df_split2.columns\n",
    "                # Clear the columns to use set_col_header function\n",
    "                df_split2.columns = [\"\" for x in columns_temp]\n",
    "                if not any(df_split2.iloc[0, 1:].str.contains('\\d')):\n",
    "                    df_split2.columns=df_split2.iloc[0]\n",
    "                    df_split2=df_split2.iloc[1:]\n",
    "                df_split2 = set_col_headers(df_split2)\n",
    "                # Use original columns if empty OR if the new would_have_been column names are contained in columns_temp, or else, stick with the new ones\n",
    "                df_split2.columns = [columns_temp[k] if (re.search('[\\w]',v) == None or v in columns_temp[k]) else v for k,v in enumerate(df_split2.columns)]\n",
    "                dictionary[ticker].append(df_split1)\n",
    "                df_original = df_split2\n",
    "            # Grab the final piece of the dataframe. If splitting not occured, we will append the original and have the duplicated be handled by drop_duplicates()\n",
    "            dictionary[ticker].append(df_original)\n",
    "\n",
    "### Delete the original subtables\n",
    "    for k in flagged_dict.keys():\n",
    "        target_list = dictionary[k]\n",
    "        to_be_del = list(flagged_dict[k])\n",
    "        to_be_del.sort(reverse=True)\n",
    "        for index in to_be_del:\n",
    "            del target_list[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from zlu_functions import del_subset_col, set_col_headers, \\\n",
    "row_header_to_col,remove_rows_for_total_value,dfs_need_transpose, remove_cols_for_fair_value,collar_fill_empty,\\\n",
    "remove_empty_rows_and_cols,df_column_uniquify\n",
    "from nel_functions import delete_uninformative,delete_empty,delete_duplicated, delete_subset, get_vertically_stacked_subtables #vertically_stacked_subtable_cleaner\n",
    "from helper import volumeCleaner, dateCleaner, priceCleaner,trimDictonary,verticalSplit\n",
    "pickle_in=open('../SEC_Data/Hedge/hedge_dfs_subset_8_18.pickle','rb')\n",
    "df_dic=pickle.load(pickle_in)\n",
    "\n",
    "delete_empty(df_dic)\n",
    "df_dic = trimDictonary(df_dic,[])#remove empty list of dfs\n",
    "del_dfs_dic_0 = delete_duplicated(df_dic) #remove duplicated dfs within a list; again\n",
    "del_dfs_dic_1 = delete_subset(df_dic)\n",
    "df_dic={'SWN20100225':df_dic['SWN20100225']}\n",
    "\n",
    "# keys=set(df_dic.keys())\n",
    "# for k in keys:\n",
    "#     if 'SWN' not in k:\n",
    "#         del df_dic[k]\n",
    "\n",
    "\n",
    "with open('../SEC_Data/8_18_outputs/output_before_spliting.csv','w') as f:\n",
    "    pass\n",
    "#preprocessing for all dfs\n",
    "for k in df_dic.keys():\n",
    "    #APC patch\n",
    "    counter=0\n",
    "    if 'APC' in k:\n",
    "        for i in range(len(df_dic[k])):\n",
    "            i=i-counter\n",
    "            cond1='collar' not in \"\".join([x.lower() for x in df_dic[k][i].values.flatten()])\n",
    "            cond2='swap' not in \"\".join([x.lower() for x in df_dic[k][i].values.flatten()])\n",
    "            if cond1 and cond2: \n",
    "                counter+=1\n",
    "                del df_dic[k][i]\n",
    "    for i in range(len(df_dic[k])):\n",
    "        df=df_dic[k][i]\n",
    "        df=set_col_headers(df) #set headers\n",
    "        df=del_subset_col(df) #delete redundant cols\n",
    "        df=remove_rows_for_total_value(df) #if any row for total value; save it\n",
    "        df=remove_cols_for_fair_value(df)\n",
    "        df_dic[k][i]=df\n",
    "        with open('../SEC_Data/8_18_outputs/output_before_spliting.csv','a') as f:\n",
    "            df=df_dic[k][i]\n",
    "            f.writelines(k+'\\n'+'table:'+str(i))\n",
    "            try: df.to_csv(f,encoding='cp1252')\n",
    "            except: df.to_csv(f,encoding='utf-8')\n",
    "\n",
    "# #         print(k,'Original Table:',i,'-'*10)\n",
    "# #         display(HTML(df.to_html()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,,,,,Natural Gas (Bcf),,Fixed Price Swaps</th>\n",
       "      <th>,,,,Volume,,,</th>\n",
       "      <th>Weighted,Average,Price to be,Swapped,($/MMBtu),,,</th>\n",
       "      <th>Weighted,Average,Floor,Price,($/MMBtu),,,</th>\n",
       "      <th>Weighted,Average,Ceiling,Price,($/MMBtu),,,</th>\n",
       "      <th>Weighted,Average,Basis,Differential,($/MMBtu),,,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.04</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.69</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Costless-Collars</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010</td>\n",
       "      <td>30.0</td>\n",
       "      <td></td>\n",
       "      <td>6.80</td>\n",
       "      <td>8.43</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Basis Swaps</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010</td>\n",
       "      <td>46.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Neg0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011</td>\n",
       "      <td>9.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Neg0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Natural Gas (Bcf),,Fixed price swaps</th>\n",
       "      <th>,,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Costless-collars</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in df_dic['SWN20100225']:\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vertical Split \n",
    "for k in df_dic.keys(): #apply Sam's spliting function\n",
    "    if 'CLR' in k: continue #change 8/16/2019\n",
    "    if 'RRC' in k: df_dic[k] = verticalSplit(df_dic[k])\n",
    "    elif k=='BRY20110301':\n",
    "        split_dfs = []\n",
    "        for table in df_dic[k]:\n",
    "            df1 = table.iloc[:, 0:3]\n",
    "            df2 = table.iloc[:, 3:]\n",
    "            split_dfs.append(df1)\n",
    "            split_dfs.append(df2)\n",
    "            df_dic[k]=split_dfs\n",
    "    else: df_dic[k] = verticalSplit_ZLU(df_dic[k])\n",
    "    df_dic[k]=verticalSplit_instrument(df_dic[k])\n",
    "    if 'RRC' in k: df_dic[k] = verticalSplit(df_dic[k])\n",
    "    else: df_dic[k] = verticalSplit_ZLU(df_dic[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,,,,,natural gas (bcf),,fixed price swaps</th>\n",
       "      <th>,,,,volume,,,</th>\n",
       "      <th>weighted,average,price to be,swapped,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,floor,price,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,ceiling,price,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,basis,differential,($/mmbtu),,,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.04</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.69</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Costless-Collars</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010</td>\n",
       "      <td>30.0</td>\n",
       "      <td></td>\n",
       "      <td>6.80</td>\n",
       "      <td>8.43</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Basis Swaps</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010</td>\n",
       "      <td>46.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Neg0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011</td>\n",
       "      <td>9.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Neg0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natural gas (bcf),,fixed price swaps</th>\n",
       "      <th>,,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Costless-collars</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in df_dic['SWN20100225']:\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWN20100225\n"
     ]
    }
   ],
   "source": [
    "for k in df_dic.keys():\n",
    "    print(k)\n",
    "    for i in range(len(df_dic[k])):\n",
    "        df=df_dic[k][i]\n",
    "        if df.shape[1]==1: df=pd.DataFrame()\n",
    "        elif isinstance(df, pd.DataFrame): #after new headers; ignore empty dfs\n",
    "            df=del_subset_col(df) #delete redundant cols\n",
    "            df=remove_rows_for_total_value(df) #if any row for total value; save it\n",
    "            df=remove_cols_for_fair_value(df)\n",
    "            df=row_header_to_col(df)\n",
    "            df=dfs_need_transpose(df)\n",
    "            df=collar_fill_empty(df)\n",
    "            df=df_column_uniquify(df)\n",
    "            df_dic[k][i]=remove_empty_rows_and_cols(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_column_uniquify(dfs_need_transpose(del_subset_col(df_dic['APC20060303'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,,,,,natural gas (bcf),,fixed price swaps</th>\n",
       "      <th>,,,,volume,,,</th>\n",
       "      <th>weighted,average,price to be,swapped,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,floor,price,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,ceiling,price,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,basis,differential,($/mmbtu),,,</th>\n",
       "      <th>instrument_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.04</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.69</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010</td>\n",
       "      <td>30.0</td>\n",
       "      <td></td>\n",
       "      <td>6.80</td>\n",
       "      <td>8.43</td>\n",
       "      <td></td>\n",
       "      <td>costless-collars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010</td>\n",
       "      <td>46.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Neg0.37</td>\n",
       "      <td>basis swaps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011</td>\n",
       "      <td>9.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Neg0.35</td>\n",
       "      <td>basis swaps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natural gas (bcf),,fixed price swaps</th>\n",
       "      <th>,,</th>\n",
       "      <th>instrument_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>36.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>30.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010</td>\n",
       "      <td>30.0</td>\n",
       "      <td>costless-collars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in df_dic['SWN20100225']:\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWN20100225\n"
     ]
    }
   ],
   "source": [
    "#Vertical Split\n",
    "for k in df_dic.keys(): #apply Sam's spliting function\n",
    "    print(k)\n",
    "    if 'RRC' in k: df_dic[k] = verticalSplit(df_dic[k])\n",
    "    elif \"APC\" in k:\n",
    "        df_dic[k] = verticalSplit_instrument(df_dic[k],'two way','fixed price')\n",
    "        df_dic[k] = verticalSplit_instrument(df_dic[k],'two way','fixed price')\n",
    "        df_dic[k] = verticalSplit_instrument(df_dic[k],'two way','three way')\n",
    "        df_dic[k] = verticalSplit_instrument(df_dic[k],'three way','fixed price')\n",
    "        df_dic[k] = verticalSplit_instrument(df_dic[k],'basis swaps','fixed price')\n",
    "\n",
    "\n",
    "    else: df_dic[k] = verticalSplit_ZLU(df_dic[k])\n",
    "    df_dic[k]=verticalSplit_instrument(df_dic[k])\n",
    "   \n",
    "    for i in range(len(df_dic[k])):\n",
    "        df=df_dic[k][i]\n",
    "        if df.shape[1]==1: df=pd.DataFrame()\n",
    "        elif isinstance(df, pd.DataFrame): #after new headers; ignore empty dfs\n",
    "            df=del_subset_col(df) #delete redundant cols\n",
    "            df=remove_rows_for_total_value(df) #if any row for total value; save it\n",
    "            df=remove_cols_for_fair_value(df)\n",
    "            df=df_column_uniquify(df)\n",
    "            df=remove_empty_rows_and_cols(df)\n",
    "            \n",
    "            row_lst=list(range(df.shape[0]))\n",
    "            for ii in range(df.shape[0]):\n",
    "                if not any(df.iloc[ii].str.contains('\\d')): row_lst.remove(ii)\n",
    "            df_dic[k][i]=df.iloc[row_lst]\n",
    "            if sum(df_dic[k][i].shape)<=2: df_dic[k][i]=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,,,,,natural gas (bcf),,fixed price swaps</th>\n",
       "      <th>,,,,volume,,,</th>\n",
       "      <th>weighted,average,price to be,swapped,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,floor,price,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,ceiling,price,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,basis,differential,($/mmbtu),,,</th>\n",
       "      <th>instrument_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.04</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.69</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010</td>\n",
       "      <td>30.0</td>\n",
       "      <td></td>\n",
       "      <td>6.80</td>\n",
       "      <td>8.43</td>\n",
       "      <td></td>\n",
       "      <td>costless-collars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010</td>\n",
       "      <td>46.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Neg0.37</td>\n",
       "      <td>basis swaps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011</td>\n",
       "      <td>9.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Neg0.35</td>\n",
       "      <td>basis swaps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natural gas (bcf),,fixed price swaps</th>\n",
       "      <th>,,</th>\n",
       "      <th>instrument_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>36.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>30.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010</td>\n",
       "      <td>30.0</td>\n",
       "      <td>costless-collars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in df_dic['SWN20100225']:\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Horizontally Split\n",
    "del_dfs_dic3=get_vertically_stacked_subtables(df_dic)\n",
    "vertically_stacked_subtable_cleaner(df_dic,del_dfs_dic3,exclusion=True, excluded_ticker=('MXC', 'OXY', 'HOC'))\n",
    "\n",
    "delete_empty(df_dic)\n",
    "df_dic = trimDictonary(df_dic,[])#remove empty list of dfs\n",
    "del_dfs_dic_2 = delete_duplicated(df_dic) #remove duplicated dfs within a list; again\n",
    "del_dfs_dic_3 = delete_subset(df_dic)\n",
    "\n",
    "for k in df_dic.keys(): #apply Sam's spliting function\n",
    "    for i in range(len(df_dic[k])):\n",
    "        df=df_dic[k][i]\n",
    "        if df.shape[1]==1: df=pd.DataFrame()\n",
    "        elif isinstance(df, pd.DataFrame): #after new headers; ignore empty dfs\n",
    "            df=del_subset_col(df) #delete redundant cols\n",
    "            df_dic[k][i]=df_column_uniquify(df)\n",
    "            df_dic[k][i]=remove_empty_rows_and_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,,,,,natural gas (bcf),,fixed price swaps</th>\n",
       "      <th>,,,,volume,,,</th>\n",
       "      <th>weighted,average,price to be,swapped,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,floor,price,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,ceiling,price,($/mmbtu),,,</th>\n",
       "      <th>weighted,average,basis,differential,($/mmbtu),,,</th>\n",
       "      <th>instrument_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.04</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.69</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010</td>\n",
       "      <td>30.0</td>\n",
       "      <td></td>\n",
       "      <td>6.80</td>\n",
       "      <td>8.43</td>\n",
       "      <td></td>\n",
       "      <td>costless-collars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010</td>\n",
       "      <td>46.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Neg0.37</td>\n",
       "      <td>basis swaps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011</td>\n",
       "      <td>9.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Neg0.35</td>\n",
       "      <td>basis swaps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for df in df_dic['SWN20100225']:\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWN20100225\n"
     ]
    }
   ],
   "source": [
    "with open('../SEC_Data/8_18_outputs/output_before_sam.csv','w') as f:\n",
    "    pass\n",
    "with open('../SEC_Data/8_18_outputs/output_after_sam.csv','w') as f:\n",
    "    pass\n",
    "for k in df_dic.keys():\n",
    "    for i in range(len(df_dic[k])):\n",
    "        with open('../SEC_Data/8_18_outputs/output_before_sam.csv','a') as f:\n",
    "            df=df_dic[k][i]\n",
    "            f.writelines(k+'\\n'+'table:'+str(i))\n",
    "            try: df.to_csv(f,encoding='cp1252')\n",
    "            except: df.to_csv(f,encoding='utf-8')\n",
    "\n",
    "\n",
    "for k in df_dic.keys():\n",
    "    print(k)\n",
    "    for i in range(len(df_dic[k])):\n",
    "        df=df_dic[k][i]\n",
    "        if df.shape[0]>0: #apply Sam's functions to non-empty dfs\n",
    "#             print(k+' ,table:'+str(i)+'-----After Preprocessing----')\n",
    "#             display(HTML(df.to_html()))\n",
    "            df = dateCleaner(df, key_words = \"\", stop_words = \"\")\n",
    "            df = volumeCleaner(df, key_words = \"\", stop_words = \"\")\n",
    "            df = priceCleaner(df, key_words = \"\", stop_words = \"\")\n",
    "            print(k+' ,table:'+str(i)+'-----After Sam functions----')\n",
    "            display(HTML(df.to_html()))\n",
    "        else: df=pd.DataFrame()\n",
    "        df_dic[k][i]=df\n",
    "\n",
    "del_dfs_dic_5 = delete_uninformative(df_dic)\n",
    "# print('1',len(df_dic))\n",
    "delete_empty(df_dic)\n",
    "# print('2',len(df_dic))\n",
    "# for df in df_dic['SWN20040225']:\n",
    "#     display(HTML(df.to_html()))\n",
    "df_dic = trimDictonary(df_dic,[])#remove empty list of dfs\n",
    "# print('3',len(df_dic))\n",
    "del_dfs_dic_2 = delete_duplicated(df_dic) #remove duplicated dfs within a list; again\n",
    "# print('4',len(df_dic))\n",
    "del_dfs_dic_3 = delete_subset(df_dic)\n",
    "# print('5',len(df_dic))\n",
    "\n",
    "for k in df_dic.keys():\n",
    "    for i in range(len(df_dic[k])):\n",
    "        with open('../SEC_Data/8_18_outputs/output_after_sam.csv','a') as f:\n",
    "            df=df_dic[k][i]\n",
    "            f.writelines(k+'\\n'+'table:'+str(i))\n",
    "            try: df.to_csv(f,encoding='cp1252')\n",
    "            except: df.to_csv(f,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SWN20100225'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-264c1d8ce331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SWN20100225'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SWN20100225'"
     ]
    }
   ],
   "source": [
    "for df in df_dic['SWN20100225']:\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import pickle\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from IPython.display import display, HTML\n",
    "# from zlu_functions import del_subset_col, set_col_headers, \\\n",
    "# row_header_to_col,remove_rows_for_total_value,dfs_need_transpose, remove_cols_for_fair_value,collar_fill_empty,\\\n",
    "# remove_empty_rows_and_cols,df_column_uniquify\n",
    "# from nel_functions import delete_empty,delete_duplicated, delete_subset,get_vertically_stacked_subtables,vertically_stacked_subtable_cleaner\n",
    "# from helper import volumeCleaner, dateCleaner, priceCleaner,trimDictonary,verticalSplit\n",
    "# pickle_in=open('../SEC_Data/Hedge/hedge_dfs_all_new.pickle','rb')\n",
    "# df_dic=pickle.load(pickle_in)\n",
    "\n",
    "# # delete_empty(df_dic)\n",
    "# df_dic = trimDictonary(df_dic,[])#remove empty list of dfs\n",
    "# del_dfs_dic_0 = delete_duplicated(df_dic) #remove duplicated dfs within a list; again\n",
    "# del_dfs_dic_1 = delete_subset(df_dic)\n",
    "\n",
    "# # # del df_dic['CPE20170228']\n",
    "# df_dic_original=df_dic.copy()\n",
    "# #preprocessing for all dfs\n",
    "# for k in df_dic.keys():\n",
    "#     for i in range(len(df_dic[k])):\n",
    "#         df_dic[k][i]=set_col_headers(df_dic[k][i]) #set headers\n",
    "\n",
    "# #Vertical Split\n",
    "# for k in df_dic.keys(): #apply Sam's spliting function        \n",
    "#     if 'RRC' in k: df_dic[k] = verticalSplit(df_dic[k])\n",
    "#     elif k=='BRY20110301':\n",
    "#         split_dfs = []\n",
    "#         for table in df_dic[k]:\n",
    "#             df1 = table.iloc[:, 0:3]\n",
    "#             df2 = table.iloc[:, 3:]\n",
    "#             split_dfs.append(df1)\n",
    "#             split_dfs.append(df2)\n",
    "#             df_dic[k]=split_dfs\n",
    "#     else: df_dic[k] = verticalSplit_ZLU(df_dic[k])\n",
    "#     df_dic[k]=verticalSplit_instrument(df_dic[k])\n",
    "#     df_dic[k]=verticalSplit_ZLU(df_dic[k])\n",
    "# #         print(k,'Original Table:',i,'-'*10)\n",
    "# #         display(HTML(df.to_html()))\n",
    "# #         if df.shape[1]==1: df=pd.DataFrame()\n",
    "# #         elif isinstance(df, pd.DataFrame): #after new headers; ignore empty dfs\n",
    "# #             df=del_subset_col(df) #delete redundant cols\n",
    "# #             df=remove_rows_for_total_value(df) #if any row for total value; save it\n",
    "# #             df=remove_cols_for_fair_value(df)\n",
    "# #             df=row_header_to_col(df)\n",
    "# #             df=dfs_need_transpose(df)\n",
    "            \n",
    "\n",
    "# #             df=collar_fill_empty(df)\n",
    "# #             df_dic[k][i]=df_column_uniquify(df)\n",
    "# #             df_dic[k][i]=df\n",
    "# #             print(k,'Table:',i,'-'*10,'After preprocessing')\n",
    "# #             display(HTML(df.to_html()))\n",
    "            \n",
    "\n",
    "# # #Vertical Split\n",
    "# # for k in df_dic.keys(): #apply Sam's spliting function        \n",
    "# #     if 'RRC' in k: df_dic[k] = verticalSplit(df_dic[k])\n",
    "# #     elif k=='BRY20110301':\n",
    "# #         split_dfs = []\n",
    "# #         for table in df_dic[k]:\n",
    "# #             df1 = table.iloc[:, 0:3]\n",
    "# #             df2 = table.iloc[:, 3:]\n",
    "# #             split_dfs.append(df1)\n",
    "# #             split_dfs.append(df2)\n",
    "# #             df_dic[k]=split_dfs\n",
    "# #     else: df_dic[k] = verticalSplit_ZLU(df_dic[k])\n",
    "# #     df_dic[k]=verticalSplit_instrument(df_dic[k])\n",
    "# #     df_dic[k]=verticalSplit_ZLU(df_dic[k])\n",
    "    \n",
    "# # #Horizontally Split\n",
    "# # del_dfs_dic3=get_vertically_stacked_subtables(df_dic)\n",
    "# # vertically_stacked_subtable_cleaner(df_dic,del_dfs_dic3,exclusion=True, excluded_ticker=('MXC', 'OXY', 'HOC'))\n",
    "\n",
    "# # delete_empty(df_dic)\n",
    "# # df_dic = trimDictonary(df_dic,[])#remove empty list of dfs\n",
    "# # del_dfs_dic_2 = delete_duplicated(df_dic) #remove duplicated dfs within a list; again\n",
    "# # del_dfs_dic_3 = delete_subset(df_dic)\n",
    "\n",
    "# # for k in df_dic.keys():\n",
    "# #     i=0\n",
    "# #     for table in df_dic[k]:\n",
    "# #         print(k,'Table:',i,'-'*10)\n",
    "# #         display(HTML(table.to_html()))\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import pickle\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from IPython.display import display, HTML\n",
    "# from zlu_functions import del_subset_col, set_col_headers, \\\n",
    "# row_header_to_col,remove_rows_for_total_value,dfs_need_transpose, remove_cols_for_fair_value,collar_fill_empty,\\\n",
    "# remove_empty_rows_and_cols\n",
    "# from nel_functions import delete_duplicated, delete_subset,get_vertically_stacked_subtables\n",
    "# from helper import volumeCleaner, dateCleaner, priceCleaner,trimDictonary#,verticalSplit\n",
    "# pickle_in=open('../SEC_Data/Hedge/hedge_dfs_all_new.pickle','rb')\n",
    "# df_dic=pickle.load(pickle_in)\n",
    "\n",
    "# df_dic = trimDictonary(df_dic,[]) #remove empty list of dfs\n",
    "# del_dfs_dic = delete_duplicated(df_dic) #remove duplicated dfs within a list\n",
    "# del_dfs_dic2 = delete_subset(df_dic)\n",
    "# del df_dic['CPE20170228']\n",
    "# with open('output.csv','w') as f:\n",
    "#     pass\n",
    "# df_dic={'SWN20030218':df_dic['SWN20030218']}\n",
    "# for k in df_dic.keys():\n",
    "#     if 'SWN' in k:\n",
    "#         df_lst=[]\n",
    "#         for i in range(len(df_dic[k])):\n",
    "#             df=df_dic[k][i]\n",
    "#             display(HTML(df.to_html()))\n",
    "#             print('-'*10,'Original above',k,i)\n",
    "#             df=set_col_headers(df) #set headers\n",
    "#             df=del_subset_col(df) #delete redundant cols\n",
    "#             df=remove_rows_for_total_value(df) #if any row for total value; save it\n",
    "#             df=remove_cols_for_fair_value(df)\n",
    "#             df=row_header_to_col(df)\n",
    "#             df=dfs_need_transpose(df)\n",
    "            \n",
    "#             if 'product_type' in df.index:\n",
    "#                 list1=df.columns\n",
    "#                 list2=df.loc[['product_type','instrument_type']].apply(lambda x: \",\".join(x[:i]))\n",
    "#                 df.columns=[str(a) +','+ str(b) for a,b in zip(list1,list2)]\n",
    "#                 df=df.drop(['product_type','instrument_type'],axis=0)\n",
    "#             display(HTML(df.to_html()))\n",
    "#             df_dic[k][i]=df\n",
    "#         df_dic[k]=verticalSplit_ZLU(df_dic[k])\n",
    "#         df_dic[k]=verticalSplit_instrument(df_dic[k])\n",
    "#         df_dic[k]=verticalSplit_ZLU(df_dic[k])\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
